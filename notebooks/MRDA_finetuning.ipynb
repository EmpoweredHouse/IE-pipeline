{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be9add11",
   "metadata": {},
   "source": [
    "# MRDA Dialogue Act Classification Pipeline\n",
    "\n",
    "## Multi-Stage Training Approach:\n",
    "1. **Stage 1:** Train 12-class General DA classifier \n",
    "2. **Stage 2:** Map to binary content/non-content classification\n",
    "\n",
    "**Target Model Repository:** `wylupek/distilbert-mrda-dialogue-acts`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0b6267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filip/Documents/github/IE-pipeline/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import platform\n",
    "import psutil\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig, \n",
    "    get_peft_model, \n",
    "    TaskType,\n",
    "    PeftModel\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from huggingface_hub import login, whoami\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d95a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Linux 5.15.0-151-generic\n",
      "Architecture: x86_64\n",
      "CPU Cores: 24\n",
      "RAM: 31.2 GB\n",
      "CUDA Device: NVIDIA GeForce RTX 3060 Ti\n",
      "GPU Memory: 7.8 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"Architecture: {platform.machine()}\")\n",
    "print(f\"CPU Cores: {psutil.cpu_count()}\")\n",
    "print(f\"RAM: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "\n",
    "\n",
    "def detect_device():\n",
    "    \"\"\"Detect best available device with fallback strategy\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        device_name = torch.cuda.get_device_name(0)\n",
    "        memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        print(f\"CUDA Device: {device_name}\")\n",
    "        print(f\"GPU Memory: {memory_gb:.1f} GB\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = \"mps\" \n",
    "        device_name = \"Apple Silicon (MPS)\"\n",
    "        print(f\"MPS Device: {device_name}\")\n",
    "        print(f\"Unified Memory Available\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        device_name = \"CPU\"\n",
    "        print(f\"CPU Device: {device_name}\")\n",
    "        print(f\"Using CPU cores: {psutil.cpu_count()}\")\n",
    "    \n",
    "    return device, device_name\n",
    "\n",
    "device, device_name = detect_device()\n",
    "\n",
    "# Test device\n",
    "try:\n",
    "    test_tensor = torch.randn(10, 10).to(device)\n",
    "    result = torch.matmul(test_tensor, test_tensor.T)\n",
    "    del test_tensor, result\n",
    "except Exception as e:\n",
    "    print(f\"Device Test Failed: {e}\")\n",
    "    print(\"Falling back to CPU...\")\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0253782d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits:\n",
      "  train: 75,067 samples\n",
      "  test: 16,702 samples\n",
      "  validation: 16,433 samples\n",
      "  Total: 108,202 samples\n",
      "\n",
      "Sample data: {'speaker': 'fe016', 'text': 'okay.', 'basic_da': 'F', 'general_da': 'fg', 'full_da': 'fg'}\n",
      "Unique general_da labels: 12\n",
      "Labels: ['%', 'b', 'fg', 'fh', 'h', 'qh', 'qo', 'qr', 'qrr', 'qw', 'qy', 's']\n",
      "\n",
      "Label Distribution (Training Set):\n",
      "  %: 440 samples (2.7%)\n",
      "  b: 2,342 samples (14.3%)\n",
      "  fg: 527 samples (3.2%)\n",
      "  fh: 1,225 samples (7.5%)\n",
      "  h: 184 samples (1.1%)\n",
      "  qh: 36 samples (0.2%)\n",
      "  qo: 25 samples (0.2%)\n",
      "  qr: 39 samples (0.2%)\n",
      "  qrr: 73 samples (0.4%)\n",
      "  qw: 287 samples (1.7%)\n",
      "  qy: 806 samples (4.9%)\n",
      "  s: 10,449 samples (63.6%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset(\"wylupek/mrda-corpus\")\n",
    "\n",
    "print(f\"Dataset splits:\")\n",
    "for split_name, split_data in dataset.items():\n",
    "    print(f\"  {split_name}: {len(split_data):,} samples\")\n",
    "total_samples = sum(len(split) for split in dataset.values())\n",
    "print(f\"  Total: {total_samples:,} samples\\n\")\n",
    "\n",
    "print(f\"Sample data: {dataset['train'][0]}\")\n",
    "\n",
    "\n",
    "train_labels = [sample['general_da'] for sample in dataset['validation']]\n",
    "unique_labels = list(set(train_labels))\n",
    "unique_labels.sort()\n",
    "print(f\"Unique general_da labels: {len(unique_labels)}\")\n",
    "print(f\"Labels: {unique_labels}\\n\")\n",
    "\n",
    "\n",
    "label_counts = pd.Series(train_labels).value_counts().sort_index()\n",
    "print(f\"Label Distribution (Training Set):\")\n",
    "for label, count in label_counts.items():\n",
    "    percentage = (count / len(train_labels)) * 100\n",
    "    print(f\"  {label}: {count:,} samples ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a79a2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split:\n",
      "  Content: 54,123 samples (72.1%)\n",
      "  Non-content: 20,944 samples (27.9%)\n",
      "Validation split:\n",
      "  Content: 11,715 samples (71.3%)\n",
      "  Non-content: 4,718 samples (28.7%)\n",
      "Test split:\n",
      "  Content: 11,848 samples (70.9%)\n",
      "  Non-content: 4,854 samples (29.1%)\n"
     ]
    }
   ],
   "source": [
    "CONTENT_LABELS = {\n",
    "    's',      # Statement (65.2% - main content)\n",
    "    'qy',     # Yes-No-question (4.4%)\n",
    "    'qw',     # Wh-Question (1.5%)\n",
    "    'qh',     # Rhetorical Question (0.3%)\n",
    "    'qrr',    # Or-Clause (0.3%)\n",
    "    'qr',     # Or Question (0.2%)\n",
    "    'qo'      # Open-ended Question (0.2%)\n",
    "}\n",
    "\n",
    "NON_CONTENT_LABELS = {\n",
    "    'b',      # Continuer (14.1% - backchannels)\n",
    "    'fh',     # Floor Holder (7.5% - floor management)\n",
    "    'fg',     # Floor Grabber (2.8% - floor management)\n",
    "    '%',      # Interrupted/Abandoned (2.9% - disruptions)\n",
    "    'h'       # Hold Before Answer (0.6% - hesitations)\n",
    "}\n",
    "\n",
    "def calculate_content_distribution(labels):\n",
    "    \"\"\"Calculate content vs non-content percentages\"\"\"\n",
    "    content_count = sum(1 for label in labels if label in CONTENT_LABELS)\n",
    "    non_content_count = sum(1 for label in labels if label in NON_CONTENT_LABELS)\n",
    "    total = len(labels)\n",
    "    \n",
    "    content_pct = (content_count / total) * 100\n",
    "    non_content_pct = (non_content_count / total) * 100\n",
    "    \n",
    "    return content_count, non_content_count, content_pct, non_content_pct\n",
    "\n",
    "def map_to_binary(general_da_label):\n",
    "    \"\"\"Map general DA label to binary content/non-content\"\"\"\n",
    "    if general_da_label in CONTENT_LABELS:\n",
    "        return 1  # Content\n",
    "    elif general_da_label in NON_CONTENT_LABELS:\n",
    "        return 0  # Non-content\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown label: {general_da_label}\")\n",
    "\n",
    "def map_to_text(general_da_label):\n",
    "    \"\"\"Map general DA label to text description\"\"\"\n",
    "    if general_da_label in CONTENT_LABELS:\n",
    "        return \"content\"\n",
    "    elif general_da_label in NON_CONTENT_LABELS:\n",
    "        return \"non-content\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown label: {general_da_label}\")\n",
    "\n",
    "\n",
    "for split_name in ['train', 'validation', 'test']:\n",
    "    split_labels = [sample['general_da'] for sample in dataset[split_name]]\n",
    "    content_count, non_content_count, content_pct, non_content_pct = calculate_content_distribution(split_labels)\n",
    "    \n",
    "    print(f\"{split_name.capitalize()} split:\")\n",
    "    print(f\"  Content: {content_count:,} samples ({content_pct:.1f}%)\")\n",
    "    print(f\"  Non-content: {non_content_count:,} samples ({non_content_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132962f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample text: 'okay so um i was going to try to get out of here'\n",
      "Tokenized shape: torch.Size([1, 15])\n",
      "Tokens: [101, 3100, 2061, 8529, 1045, 2001, 2183, 2000, 3046, 2000, 2131, 2041, 1997, 2182, 102]\n",
      "\n",
      "Logits shape: torch.Size([1, 12])\n",
      "Predictions: [0.07466944307088852, 0.09711909294128418, 0.08354572206735611, 0.08508571237325668, 0.08700844645500183, 0.0856059193611145, 0.07023141533136368, 0.0793866217136383, 0.07778478413820267, 0.09030162543058395, 0.08108097314834595, 0.08818024396896362]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "NUM_LABELS = 12\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_LABELS,\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Test tokenization\n",
    "sample_text = \"okay so um i was going to try to get out of here\"\n",
    "encoded = tokenizer(sample_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "print(f\"\\nSample text: '{sample_text}'\")\n",
    "print(f\"Tokenized shape: {encoded['input_ids'].shape}\")\n",
    "print(f\"Tokens: {encoded['input_ids'][0].tolist()}\\n\")\n",
    "\n",
    "\n",
    "encoded = encoded.to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Predictions: {predictions.tolist()[0]}\")\n",
    "\n",
    "del encoded, outputs, logits, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03248c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping:\n",
      "  % -> 0\n",
      "  b -> 1\n",
      "  fg -> 2\n",
      "  fh -> 3\n",
      "  h -> 4\n",
      "  qh -> 5\n",
      "  qo -> 6\n",
      "  qr -> 7\n",
      "  qrr -> 8\n",
      "  qw -> 9\n",
      "  qy -> 10\n",
      "  s -> 11\n",
      "\n",
      "Max length: 96\n"
     ]
    }
   ],
   "source": [
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(\"Label mapping:\")\n",
    "for label, idx in label2id.items():\n",
    "    print(f\"  {label} -> {idx}\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Tokenize text and encode labels\"\"\"\n",
    "    tokens = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=False,  # Will pad later in DataCollator\n",
    "        max_length=128,  # Actual max length is 96\n",
    "        return_tensors=None\n",
    "    )\n",
    "    tokens[\"labels\"] = [label2id[label] for label in examples[\"general_da\"]]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to all splits\n",
    "tokenized_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    desc=\"Tokenizing\"\n",
    ")\n",
    "\n",
    "# Verify no data loss\n",
    "if len(dataset[\"train\"]) != len(tokenized_datasets[\"train\"]):\n",
    "    print(f\"Not all samples were processed\\n\")\n",
    "    print(f\"Original train size: {len(dataset['train']):,}\")\n",
    "    print(f\"Processed train size: {len(tokenized_datasets['train']):,}\")\n",
    "if len(dataset[\"validation\"]) != len(tokenized_datasets[\"validation\"]):\n",
    "    print(f\"Not all samples were processed\\n\")\n",
    "    print(f\"Original validation size: {len(dataset['validation']):,}\")\n",
    "    print(f\"Processed validation size: {len(tokenized_datasets['validation']):,}\")\n",
    "if len(dataset[\"test\"]) != len(tokenized_datasets[\"test\"]):\n",
    "    print(f\"Not all samples were processed\\n\")\n",
    "    print(f\"Original test size: {len(dataset['test']):,}\")\n",
    "    print(f\"Processed test size: {len(tokenized_datasets['test']):,}\")\n",
    "\n",
    "# Check max length\n",
    "print(\"\\nMax length:\", max(max(len(s[\"input_ids\"]) for s in tokenized_datasets[split]) for split in [\"train\",\"validation\",\"test\"]))\n",
    "\n",
    "# Create data collator for batching\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b82e789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights (balanced method):\n",
      "  0 (%): 0.796 (count: 2171)\n",
      "  1 (b): 0.383 (count: 10606)\n",
      "  2 (fg): 0.820 (count: 2076)\n",
      "  3 (fh): 0.478 (count: 5617)\n",
      "  4 (h): 2.656 (count: 474)\n",
      "  5 (qh): 4.615 (count: 260)\n",
      "  6 (qo): 10.000 (count: 116)\n",
      "  7 (qr): 8.887 (count: 131)\n",
      "  8 (qrr): 4.899 (count: 244)\n",
      "  9 (qw): 1.293 (count: 1110)\n",
      "  10 (qy): 0.618 (count: 3310)\n",
      "  11 (s): 0.300 (count: 48952)\n"
     ]
    }
   ],
   "source": [
    "MAX_WEIGHT = 10\n",
    "MIN_WEIGHT = 0.3\n",
    "\n",
    "raw_train_labels = [sample[\"labels\"] for sample in tokenized_datasets[\"train\"]]\n",
    "total_train_examples = len(raw_train_labels)\n",
    "train_label_counts = dict(sorted(Counter(raw_train_labels).items(), key=lambda x: x[0]))\n",
    "\n",
    "# Compute weights\n",
    "class_weights = [1 / x for x in train_label_counts.values()]\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Scale weights to MAX_WEIGHT and MIN_WEIGHT\n",
    "curr_max_weight = class_weights_tensor.max()\n",
    "curr_min_weight = class_weights_tensor.min()\n",
    "class_weights_tensor = (class_weights_tensor - curr_min_weight) / (curr_max_weight - curr_min_weight) * (MAX_WEIGHT - MIN_WEIGHT) + MIN_WEIGHT\n",
    "\n",
    "print(f\"Class weights (balanced method):\")\n",
    "for class_id in range(NUM_LABELS):\n",
    "    print(f\"  {class_id} ({id2label[class_id]}): {class_weights_tensor[class_id].item() :.3f} (count: {train_label_counts[class_id]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99bce13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal loss with balanced cross entropy\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# Custom Weighted Trainer\n",
    "class AdvancedTrainer(Trainer):\n",
    "    def __init__(self, loss_type=\"focal\", class_weights=None, focal_gamma=2.0, loss_reduction=\"mean\", *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_type = loss_type\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "        if loss_type == \"focal\":\n",
    "            self.loss_fn = FocalLoss(alpha=class_weights, gamma=focal_gamma, reduction=loss_reduction)\n",
    "        elif loss_type == \"weighted_ce\":\n",
    "            self.loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        else:\n",
    "            self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        \n",
    "        loss = self.loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    macro_f1 = f1_score(labels, predictions, average='macro')\n",
    "    micro_f1 = f1_score(labels, predictions, average='micro')\n",
    "    weighted_f1 = f1_score(labels, predictions, average='weighted')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"micro_f1\": micro_f1,\n",
    "        \"weighted_f1\": weighted_f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "115113c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.00046061722708429296, 1: 9.428625306430322e-05, 2: 0.0004816955684007707, 3: 0.00017803097739006588, 4: 0.002109704641350211, 5: 0.0038461538461538464, 6: 0.008620689655172414, 7: 0.007633587786259542, 8: 0.004098360655737705, 9: 0.0009009009009009009, 10: 0.00030211480362537764, 11: 2.0428174538323256e-05}\n"
     ]
    }
   ],
   "source": [
    "# TODO the trainer isn't using stratified sampling\n",
    "# 4. Stratified Batch Sampling\n",
    "def create_stratified_sampler(dataset):\n",
    "    # Get labels from dataset\n",
    "    labels = [sample[\"labels\"] for sample in dataset]\n",
    "    \n",
    "    # Calculate sample weights for stratified sampling - handle non-contiguous labels\n",
    "    unique_labels_in_data = sorted(set(labels))\n",
    "    class_sample_count = {label: labels.count(label) for label in unique_labels_in_data}\n",
    "    \n",
    "    # Create weight mapping for each class\n",
    "    weight_mapping = {}\n",
    "    for label, count in class_sample_count.items():\n",
    "        weight_mapping[label] = 1.0 / count\n",
    "    \n",
    "    # Assign weight to each sample\n",
    "    samples_weight = torch.tensor([weight_mapping[label] for label in labels])\n",
    "    print(weight_mapping)\n",
    "    # Create sampler\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=samples_weight,\n",
    "        num_samples=len(samples_weight),\n",
    "        replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "# Create stratified sampler\n",
    "train_sampler = create_stratified_sampler(tokenized_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff815852",
   "metadata": {},
   "source": [
    "### Parameters tuning\n",
    "**LoRA**\n",
    "- lora_dropout – Regular dropout regularization, prevents overfitting. (0.0; 0.3)\n",
    "- lora_r – The size of LoRA adapters, means how much new information the model can learn. High values cause better learning capacity, especially usefull for imbalanced data  (8; 64)\n",
    "- lora_alpha – How strong the LoRA adapters influence the original model. Affects effective scaling (`lora_alpha/lora_r`) (scale between 0.5 and 8)\n",
    "\n",
    "**Traning arguments**\n",
    "\n",
    "NOTE: Step is calculated by `ceil(total_samples / batch_size)`\n",
    "\n",
    "Proper Warmup Guidelines:\n",
    "- Simple tasks: 5-10% of total steps\n",
    "- Complex tasks: 10-15% of total steps\n",
    "- Imbalanced/Difficult: 15-20% of total steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e9e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps: 14076\n",
      "Steps per epoch: 2346\n",
      "Steps per eval: 391\n",
      "Steps per logging: 195\n",
      "Steps per saving: 1173\n"
     ]
    }
   ],
   "source": [
    "LORA_DROPOUT = 0.15\n",
    "LORA_R = 64\n",
    "LORA_ALPHA = 128\n",
    "\n",
    "LOSS_TYPE = \"focal\"\n",
    "NO_EPOCHS = 6\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001\n",
    "WARMUP_STEPS = 0.15\n",
    "WEIGHT_DECAY = 0.04\n",
    "\n",
    "FOCAL_GAMMA=2.0\n",
    "LOSS_REDUCTION=\"mean\"\n",
    "\n",
    "### LoRA setup ###\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    target_modules=[\"q_lin\", \"v_lin\", \"k_lin\", \"out_lin\"],\n",
    "    modules_to_save=[\"pre_classifier\", \"classifier\"],  # Keep classification head trainable!\n",
    "    ### TUNABLE PARAMETERS ###\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    ")\n",
    "advanced_peft_model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Check which parameters are trainable\n",
    "print(\"\\n=== Trainable Parameters Check ===\")\n",
    "for name, param in advanced_peft_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"✅ {name}: {param.shape}\")\n",
    "    elif \"classifier\" in name or \"pre_classifier\" in name:\n",
    "        print(f\"❌ FROZEN: {name}: {param.shape}\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\nTotal trainable parameters: {sum(p.numel() for p in advanced_peft_model.parameters() if p.requires_grad):,}\")\n",
    "print(f\"Classifier head status: {'✅ TRAINABLE' if any('classifier' in name for name, p in advanced_peft_model.named_parameters() if p.requires_grad) else '❌ FROZEN'}\")\n",
    "\n",
    "### Training setup ###\n",
    "total_steps = NO_EPOCHS * np.ceil(len(tokenized_datasets[\"train\"]) / BATCH_SIZE)\n",
    "eval_steps = total_steps // NO_EPOCHS // 6 # 6 times per epoch\n",
    "save_steps = eval_steps * 3 # 3 times per epoch\n",
    "logging_steps = total_steps // NO_EPOCHS // 12 # 12 times per epoch\n",
    "advanced_training_args = TrainingArguments(\n",
    "    output_dir=\"./advanced_checkpoints\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",  # Optimize for macro F1, perfect for imbalanced data\n",
    "    greater_is_better=True,\n",
    "    report_to=None,\n",
    "    remove_unused_columns=False, # Required for custom trainer\n",
    "    dataloader_num_workers=0,  # Important for MPS compatibility\n",
    "    eval_steps=eval_steps,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    ### TUNABLE PARAMETERS ###\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=NO_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=int(WARMUP_STEPS * total_steps), # Prevents overfitting, should be ~15% of total steps for imbalanced data\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "advanced_trainer = AdvancedTrainer(\n",
    "    loss_type=LOSS_TYPE,  # Focal loss for imbalanced data\n",
    "    class_weights=class_weights_tensor, # Weights for imbalanced data\n",
    "    model=advanced_peft_model,\n",
    "    args=advanced_training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    ### TUNABLE PARAMETERS ###\n",
    "    focal_gamma=FOCAL_GAMMA,\n",
    "    loss_reduction=LOSS_REDUCTION,\n",
    ")\n",
    "\n",
    "print(f\"Total steps: {int(total_steps)}\")\n",
    "print(f\"Steps per epoch: {int(total_steps // NO_EPOCHS)}\")\n",
    "print(f\"Steps per eval: {int(eval_steps)}\")\n",
    "print(f\"Steps per logging: {int(logging_steps)}\")\n",
    "print(f\"Steps per saving: {int(save_steps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5d3c93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting advanced training with:\n",
      "{'max_weight': 10, 'min_weight': 0.3, 'lora_dropout': 0.15, 'lora_r': 64, 'lora_alpha': 128, 'loss_type': 'focal', 'no_epochs': 6, 'batch_size': 32, 'learning_rate': 0.0001, 'warmup_steps': 0.15, 'weight_decay': 0.04, 'max_grad_norm': 1.0, 'focal_gamma': 2.0, 'loss_reduction': 'mean'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14076' max='14076' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14076/14076 21:44, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Weighted F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>391</td>\n",
       "      <td>0.448500</td>\n",
       "      <td>0.456442</td>\n",
       "      <td>0.775817</td>\n",
       "      <td>0.248688</td>\n",
       "      <td>0.775817</td>\n",
       "      <td>0.741483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>782</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.305745</td>\n",
       "      <td>0.755979</td>\n",
       "      <td>0.416966</td>\n",
       "      <td>0.755979</td>\n",
       "      <td>0.763666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1173</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.248026</td>\n",
       "      <td>0.759021</td>\n",
       "      <td>0.437196</td>\n",
       "      <td>0.759021</td>\n",
       "      <td>0.772824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1564</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.203688</td>\n",
       "      <td>0.757744</td>\n",
       "      <td>0.476281</td>\n",
       "      <td>0.757744</td>\n",
       "      <td>0.772239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1955</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.191236</td>\n",
       "      <td>0.769367</td>\n",
       "      <td>0.519548</td>\n",
       "      <td>0.769367</td>\n",
       "      <td>0.781363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2346</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.196690</td>\n",
       "      <td>0.716911</td>\n",
       "      <td>0.480123</td>\n",
       "      <td>0.716911</td>\n",
       "      <td>0.743466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2737</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.193280</td>\n",
       "      <td>0.750259</td>\n",
       "      <td>0.523584</td>\n",
       "      <td>0.750259</td>\n",
       "      <td>0.770414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3128</td>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.202966</td>\n",
       "      <td>0.756587</td>\n",
       "      <td>0.517940</td>\n",
       "      <td>0.756587</td>\n",
       "      <td>0.775640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3519</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.184291</td>\n",
       "      <td>0.776304</td>\n",
       "      <td>0.554355</td>\n",
       "      <td>0.776304</td>\n",
       "      <td>0.789998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3910</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>0.192570</td>\n",
       "      <td>0.731394</td>\n",
       "      <td>0.527420</td>\n",
       "      <td>0.731394</td>\n",
       "      <td>0.758007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4301</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>0.191666</td>\n",
       "      <td>0.745573</td>\n",
       "      <td>0.559581</td>\n",
       "      <td>0.745573</td>\n",
       "      <td>0.774308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4692</td>\n",
       "      <td>0.151700</td>\n",
       "      <td>0.195552</td>\n",
       "      <td>0.761151</td>\n",
       "      <td>0.525092</td>\n",
       "      <td>0.761151</td>\n",
       "      <td>0.775100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5083</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.190417</td>\n",
       "      <td>0.771861</td>\n",
       "      <td>0.570988</td>\n",
       "      <td>0.771861</td>\n",
       "      <td>0.788089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5474</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>0.228432</td>\n",
       "      <td>0.765168</td>\n",
       "      <td>0.544898</td>\n",
       "      <td>0.765168</td>\n",
       "      <td>0.780021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5865</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.197431</td>\n",
       "      <td>0.771314</td>\n",
       "      <td>0.557156</td>\n",
       "      <td>0.771314</td>\n",
       "      <td>0.788377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6256</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.197287</td>\n",
       "      <td>0.765046</td>\n",
       "      <td>0.549609</td>\n",
       "      <td>0.765046</td>\n",
       "      <td>0.780750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6647</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.196340</td>\n",
       "      <td>0.746973</td>\n",
       "      <td>0.560771</td>\n",
       "      <td>0.746973</td>\n",
       "      <td>0.773786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7038</td>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.187811</td>\n",
       "      <td>0.761456</td>\n",
       "      <td>0.565507</td>\n",
       "      <td>0.761456</td>\n",
       "      <td>0.778405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7429</td>\n",
       "      <td>0.124800</td>\n",
       "      <td>0.202613</td>\n",
       "      <td>0.784336</td>\n",
       "      <td>0.565701</td>\n",
       "      <td>0.784336</td>\n",
       "      <td>0.797152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7820</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.186790</td>\n",
       "      <td>0.759873</td>\n",
       "      <td>0.561810</td>\n",
       "      <td>0.759873</td>\n",
       "      <td>0.780546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8211</td>\n",
       "      <td>0.108500</td>\n",
       "      <td>0.205955</td>\n",
       "      <td>0.777764</td>\n",
       "      <td>0.571886</td>\n",
       "      <td>0.777764</td>\n",
       "      <td>0.791164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8602</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.200646</td>\n",
       "      <td>0.759021</td>\n",
       "      <td>0.555087</td>\n",
       "      <td>0.759021</td>\n",
       "      <td>0.779743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8993</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.196893</td>\n",
       "      <td>0.765654</td>\n",
       "      <td>0.558505</td>\n",
       "      <td>0.765654</td>\n",
       "      <td>0.782383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9384</td>\n",
       "      <td>0.143400</td>\n",
       "      <td>0.193924</td>\n",
       "      <td>0.765350</td>\n",
       "      <td>0.548251</td>\n",
       "      <td>0.765350</td>\n",
       "      <td>0.782343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9775</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.194487</td>\n",
       "      <td>0.761395</td>\n",
       "      <td>0.555831</td>\n",
       "      <td>0.761395</td>\n",
       "      <td>0.780474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10166</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>0.198961</td>\n",
       "      <td>0.776425</td>\n",
       "      <td>0.565410</td>\n",
       "      <td>0.776425</td>\n",
       "      <td>0.791701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10557</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>0.199172</td>\n",
       "      <td>0.761577</td>\n",
       "      <td>0.564883</td>\n",
       "      <td>0.761577</td>\n",
       "      <td>0.782003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10948</td>\n",
       "      <td>0.104700</td>\n",
       "      <td>0.211173</td>\n",
       "      <td>0.745390</td>\n",
       "      <td>0.574744</td>\n",
       "      <td>0.745390</td>\n",
       "      <td>0.773786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11339</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>0.767541</td>\n",
       "      <td>0.565476</td>\n",
       "      <td>0.767541</td>\n",
       "      <td>0.785288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11730</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.211079</td>\n",
       "      <td>0.771436</td>\n",
       "      <td>0.575027</td>\n",
       "      <td>0.771436</td>\n",
       "      <td>0.787127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12121</td>\n",
       "      <td>0.111700</td>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.763525</td>\n",
       "      <td>0.562224</td>\n",
       "      <td>0.763525</td>\n",
       "      <td>0.781003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12512</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.201658</td>\n",
       "      <td>0.760908</td>\n",
       "      <td>0.561620</td>\n",
       "      <td>0.760908</td>\n",
       "      <td>0.780513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12903</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.204531</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.563059</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.784746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13294</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.208681</td>\n",
       "      <td>0.767541</td>\n",
       "      <td>0.561044</td>\n",
       "      <td>0.767541</td>\n",
       "      <td>0.785267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13685</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.204573</td>\n",
       "      <td>0.765715</td>\n",
       "      <td>0.563527</td>\n",
       "      <td>0.765715</td>\n",
       "      <td>0.783759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14076</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.203495</td>\n",
       "      <td>0.764498</td>\n",
       "      <td>0.567269</td>\n",
       "      <td>0.764498</td>\n",
       "      <td>0.783628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Advanced training completed!\n",
      "Final train loss: 0.1602\n"
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    \"max_weight\": MAX_WEIGHT,\n",
    "    \"min_weight\": MIN_WEIGHT,\n",
    "\n",
    "    \"lora_dropout\": LORA_DROPOUT,\n",
    "    \"lora_r\": LORA_R,\n",
    "    \"lora_alpha\": LORA_ALPHA, \n",
    "\n",
    "    \"loss_type\": LOSS_TYPE,\n",
    "    \"no_epochs\": NO_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"warmup_steps\": WARMUP_STEPS,\n",
    "    \"weight_decay\": WEIGHT_DECAY,\n",
    "\n",
    "    \"focal_gamma\": FOCAL_GAMMA,\n",
    "    \"loss_reduction\": LOSS_REDUCTION,\n",
    "}\n",
    "\n",
    "print(f\"\\nStarting advanced training with:\")\n",
    "print(hyperparams)\n",
    "\n",
    "# Run advanced training\n",
    "advanced_result = advanced_trainer.train()\n",
    "\n",
    "print(f\"\\nAdvanced training completed!\")\n",
    "print(f\"Final train loss: {advanced_result.training_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65b11942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PER-CLASS CONFUSION ANALYSIS (12 TABLES)\n",
      "================================================================================\n",
      "\n",
      "📊 CLASS 0: '%' Analysis\n",
      "--------------------------------------------------\n",
      "  Confusion:    TP= 343 | FP= 562\n",
      "                FN=  97 | TN=15431\n",
      "  Metrics:      Prec=0.379 | Rec=0.780 | F1=0.510\n",
      "  Distribution: True=  2.7% | Pred=  5.5% | Diff= +2.8%\n",
      "\n",
      "📊 CLASS 1: 'b' Analysis\n",
      "--------------------------------------------------\n",
      "  Confusion:    TP=2094 | FP=1097\n",
      "                FN= 248 | TN=12994\n",
      "  Metrics:      Prec=0.656 | Rec=0.894 | F1=0.757\n",
      "  Distribution: True= 14.3% | Pred= 19.4% | Diff= +5.2%\n",
      "\n",
      "📊 CLASS 2: 'fg' Analysis\n",
      "--------------------------------------------------\n",
      "  Confusion:    TP= 146 | FP= 506\n",
      "                FN= 381 | TN=15400\n",
      "  Metrics:      Prec=0.224 | Rec=0.277 | F1=0.248\n",
      "  Distribution: True=  3.2% | Pred=  4.0% | Diff= +0.8%\n",
      "\n",
      "📊 CLASS 3: 'fh' Analysis\n",
      "--------------------------------------------------\n",
      "  Confusion:    TP= 660 | FP= 413\n",
      "                FN= 565 | TN=14795\n",
      "  Metrics:      Prec=0.615 | Rec=0.539 | F1=0.574\n",
      "  Distribution: True=  7.5% | Pred=  6.5% | Diff= -0.9%\n",
      "\n",
      "📊 CLASS 4: 'h' Analysis\n",
      "--------------------------------------------------\n",
      "  Confusion:    TP=  90 | FP= 435\n",
      "                FN=  94 | TN=15814\n",
      "  Metrics:      Prec=0.171 | Rec=0.489 | F1=0.254\n",
      "  Distribution: True=  1.1% | Pred=  3.2% | Diff= +2.1%\n",
      "\n",
      "📊 CLASS 5: 'qh' Analysis\n",
      "--------------------------------------------------\n",
      "  Confusion:    TP=  15 | FP=  55\n",
      "                FN=  21 | TN=16342\n",
      "  Metrics:      Prec=0.214 | Rec=0.417 | F1=0.283\n",
      "  Distribution: True=  0.2% | Pred=  0.4% | Diff= +0.2%\n",
      "\n",
      "📊 CLASS 6: 'qo' Analysis\n",
      "--------------------------------------------------\n",
      "  Confusion:    TP=   8 | FP=  17\n",
      "                FN=  17 | TN=16391\n",
      "  Metrics:      Prec=0.320 | Rec=0.320 | F1=0.320\n",
      "  Distribution: True=  0.2% | Pred=  0.2% | Diff= +0.0%\n",
      "\n",
      "📊 CLASS 7: 'qr' Analysis\n",
      "--------------------------------------------------\n",
      "  Confusion:    TP=  25 | FP=  21\n",
      "                FN=  14 | TN=16373\n",
      "  Metrics:      Prec=0.543 | Rec=0.641 | F1=0.588\n",
      "  Distribution: True=  0.2% | Pred=  0.3% | Diff= +0.0%\n",
      "\n",
      "📊 CLASS 8: 'qrr' Analysis\n",
      "--------------------------------------------------\n",
      "  Confusion:    TP=  65 | FP=  27\n",
      "                FN=   8 | TN=16333\n",
      "  Metrics:      Prec=0.707 | Rec=0.890 | F1=0.788\n",
      "  Distribution: True=  0.4% | Pred=  0.6% | Diff= +0.1%\n",
      "\n",
      "📊 CLASS 9: 'qw' Analysis\n",
      "--------------------------------------------------\n",
      "  Confusion:    TP= 238 | FP=  58\n",
      "                FN=  49 | TN=16088\n",
      "  Metrics:      Prec=0.804 | Rec=0.829 | F1=0.816\n",
      "  Distribution: True=  1.7% | Pred=  1.8% | Diff= +0.1%\n",
      "\n",
      "📊 CLASS 10: 'qy' Analysis\n",
      "--------------------------------------------------\n",
      "  Confusion:    TP= 721 | FP=  74\n",
      "                FN=  85 | TN=15553\n",
      "  Metrics:      Prec=0.907 | Rec=0.895 | F1=0.901\n",
      "  Distribution: True=  4.9% | Pred=  4.8% | Diff= -0.1%\n",
      "\n",
      "📊 CLASS 11: 's' Analysis\n",
      "--------------------------------------------------\n",
      "  Confusion:    TP=8272 | FP= 491\n",
      "                FN=2177 | TN=5493\n",
      "  Metrics:      Prec=0.944 | Rec=0.792 | F1=0.861\n",
      "  Distribution: True= 63.6% | Pred= 53.3% | Diff=-10.3%\n",
      "\n",
      "🎯 OVERALL: Acc=0.771 | MacroF1=0.575 | WeightedF1=0.787\n",
      "💾 Training progress saved with 37 checkpoints\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXPERIMENT LOGGING & COMPREHENSIVE EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def setup_experiment_logging(experiment_name, hyperparams):\n",
    "    \"\"\"Setup timestamped logging directory for experiments\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = f\"results/{experiment_name}_{timestamp}\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Save hyperparameters for reproducibility\n",
    "    with open(f\"{results_dir}/hyperparams.json\", 'w') as f:\n",
    "        json.dump(hyperparams, f, indent=2)\n",
    "    \n",
    "    return results_dir\n",
    "\n",
    "\n",
    "def comprehensive_evaluation(trainer, tokenized_datasets, id2label, results_dir):\n",
    "    \"\"\"\n",
    "    Complete evaluation with:\n",
    "    - Overall metrics (accuracy, macro/weighted F1)\n",
    "    - Per-class metrics and confusion matrix\n",
    "    - Training progress table with all checkpoints\n",
    "    - Detailed 12-class analysis with TP/FP/FN/TN breakdown\n",
    "    \"\"\"\n",
    "    \n",
    "    # ===== GET PREDICTIONS =====\n",
    "    predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "    y_true = predictions.label_ids\n",
    "    y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "    \n",
    "    # ===== OVERALL METRICS =====\n",
    "    metrics = {\n",
    "        'accuracy': round(accuracy_score(y_true, y_pred), 4),\n",
    "        'macro_f1': round(f1_score(y_true, y_pred, average='macro'), 4),\n",
    "        'weighted_f1': round(f1_score(y_true, y_pred, average='weighted'), 4),\n",
    "    }\n",
    "    \n",
    "    # ===== PER-CLASS METRICS =====\n",
    "    class_report = classification_report(\n",
    "        y_true, y_pred,\n",
    "        target_names=[id2label[i] for i in range(len(id2label))],\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    def round_nested_dict(d, decimals=4):\n",
    "        \"\"\"Recursively round all numeric values in nested dictionary\"\"\"\n",
    "        if isinstance(d, dict):\n",
    "            return {k: round_nested_dict(v, decimals) for k, v in d.items()}\n",
    "        elif isinstance(d, (int, float)):\n",
    "            return round(d, decimals) if isinstance(d, float) else d\n",
    "        else:\n",
    "            return d\n",
    "    \n",
    "    class_report = round_nested_dict(class_report)\n",
    "    \n",
    "    # ===== CONFUSION MATRIX =====\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # ===== TRAINING PROGRESS EXTRACTION =====\n",
    "    training_progress = []\n",
    "    if hasattr(trainer, 'state') and hasattr(trainer.state, 'log_history'):\n",
    "        # Separate evaluation and training logs\n",
    "        eval_logs = [log for log in trainer.state.log_history if 'eval_loss' in log]\n",
    "        train_logs = [log for log in trainer.state.log_history if 'loss' in log and 'eval_loss' not in log]\n",
    "        \n",
    "        # Map training steps to training loss\n",
    "        train_loss_map = {}\n",
    "        for log in train_logs:\n",
    "            step = log.get('step', 0)\n",
    "            if step > 0:\n",
    "                train_loss_map[step] = log.get('loss', 0)\n",
    "        \n",
    "        # Match evaluation checkpoints with training loss\n",
    "        for log in eval_logs:\n",
    "            eval_step = log.get('step', 0)\n",
    "            \n",
    "            # Find closest training loss (≤ eval_step)\n",
    "            training_loss = 0\n",
    "            if train_loss_map:\n",
    "                valid_train_steps = [s for s in train_loss_map.keys() if s <= eval_step]\n",
    "                if valid_train_steps:\n",
    "                    closest_train_step = max(valid_train_steps)\n",
    "                    training_loss = train_loss_map[closest_train_step]\n",
    "            \n",
    "            progress_entry = {\n",
    "                'step': eval_step,\n",
    "                'training_loss': round(training_loss, 4),\n",
    "                'validation_loss': round(log.get('eval_loss', 0), 4),\n",
    "                'accuracy': round(log.get('eval_accuracy', 0), 4),\n",
    "                'macro_f1': round(log.get('eval_macro_f1', 0), 4),\n",
    "                'micro_f1': round(log.get('eval_micro_f1', 0), 4),\n",
    "                'weighted_f1': round(log.get('eval_weighted_f1', 0), 4)\n",
    "            }\n",
    "            training_progress.append(progress_entry)\n",
    "    \n",
    "    # ===== DETAILED 12-CLASS ANALYSIS =====\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PER-CLASS CONFUSION ANALYSIS (12 TABLES)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    detailed_analysis = {}\n",
    "    for class_id in range(len(id2label)):\n",
    "        class_name = id2label[class_id]\n",
    "        \n",
    "        # Calculate TP/FP/FN/TN for this class\n",
    "        tp = cm[class_id, class_id]\n",
    "        fp = cm[:, class_id].sum() - tp\n",
    "        fn = cm[class_id, :].sum() - tp\n",
    "        tn = cm.sum() - tp - fp - fn\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        # Calculate distribution percentages\n",
    "        true_count = (y_true == class_id).sum()\n",
    "        pred_count = (y_pred == class_id).sum()\n",
    "        true_pct = (true_count / len(y_true)) * 100\n",
    "        pred_pct = (pred_count / len(y_pred)) * 100\n",
    "        \n",
    "        # Store detailed analysis\n",
    "        detailed_analysis[class_name] = {\n",
    "            'tp': int(tp), 'fp': int(fp), 'fn': int(fn), 'tn': int(tn),\n",
    "            'precision': round(precision, 4), 'recall': round(recall, 4), 'f1': round(f1, 4),\n",
    "            'true_pct': round(true_pct, 4), 'pred_pct': round(pred_pct, 4), \n",
    "            'diff_pct': round(pred_pct - true_pct, 4)\n",
    "        }\n",
    "        \n",
    "        # Print formatted class analysis\n",
    "        print(f\"\\n📊 CLASS {class_id}: '{class_name}' Analysis\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"  Confusion:    TP={tp:4d} | FP={fp:4d}\")\n",
    "        print(f\"                FN={fn:4d} | TN={tn:4d}\")\n",
    "        print(f\"  Metrics:      Prec={precision:.3f} | Rec={recall:.3f} | F1={f1:.3f}\")\n",
    "        print(f\"  Distribution: True={true_pct:5.1f}% | Pred={pred_pct:5.1f}% | Diff={pred_pct-true_pct:+5.1f}%\")\n",
    "    \n",
    "    # ===== CLASS DISTRIBUTION ANALYSIS =====\n",
    "    true_dist = pd.Series(y_true).value_counts().sort_index()\n",
    "    pred_dist = pd.Series(y_pred).value_counts().sort_index()\n",
    "    \n",
    "    # ===== SAVE COMPREHENSIVE RESULTS =====\n",
    "    results = {\n",
    "        'overall_metrics': metrics,\n",
    "        'per_class_metrics': class_report,\n",
    "        'detailed_class_analysis': detailed_analysis,\n",
    "        'training_progress': training_progress,\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'true_distribution': true_dist.to_dict(),\n",
    "        'pred_distribution': pred_dist.to_dict()\n",
    "    }\n",
    "    \n",
    "    with open(f\"{results_dir}/evaluation.json\", 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    # ===== SUMMARY OUTPUT =====\n",
    "    print(f\"\\n🎯 OVERALL: Acc={metrics['accuracy']:.3f} | MacroF1={metrics['macro_f1']:.3f} | WeightedF1={metrics['weighted_f1']:.3f}\")\n",
    "    print(f\"💾 Training progress saved with {len(training_progress)} checkpoints\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RUN COMPREHENSIVE EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "results_dir = setup_experiment_logging(\"no_1\", hyperparams)\n",
    "results = comprehensive_evaluation(advanced_trainer, tokenized_datasets, id2label, results_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
